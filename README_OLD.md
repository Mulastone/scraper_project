# ğŸ  Scraper Dashboard Andorra

Dashboard interactivo para visualizaciÃ³n de propiedades inmobiliarias en Andorra, con scrapers automatizados y base de datos PostgreSQL.

![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)

**ğŸŒ Demo Live**: [scraper.arasmu.net](https://scraper.arasmu.net)

## ğŸ—ï¸ Estructura del Proyecto

```
scraper-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/           # ConfiguraciÃ³n y operaciones de BD
â”‚   â”‚   â”œâ”€â”€ connection.py   # ConexiÃ³n a PostgreSQL
â”‚   â”‚   â””â”€â”€ operations.py   # CRUD operations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ property.py     # Modelo de datos Property
â”‚   â”œâ”€â”€ scrapers/           # Scrapers principales
â”‚   â”‚   â”œâ”€â”€ finquesmarques_sql.py  # 59 propiedades
â”‚   â”‚   â”œâ”€â”€ nouaire_sql.py         # 1,521 propiedades
â”‚   â”‚   â”œâ”€â”€ expofinques_sql.py     # 56 propiedades
â”‚   â”‚   â”œâ”€â”€ claus_sql.py          # 12 propiedades (7claus.com)
â”‚   â”‚   â””â”€â”€ runner.py             # Ejecutor de todos los scrapers
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ text_cleaner.py # Limpieza y normalizaciÃ³n de texto
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile          # Imagen Docker del scraper
â”œâ”€â”€ antic/                  # Archivos obsoletos/backup
â”œâ”€â”€ docker-compose.yml      # PostgreSQL + Scraper
â”œâ”€â”€ requirements.txt        # Dependencias Python
â””â”€â”€ .gitignore             # Exclusiones Git
```

## ğŸ¯ Scrapers Activos

| Sitio Web            | Scraper                 | Propiedades | Estado         |
| -------------------- | ----------------------- | ----------- | -------------- |
| www.finquesmarca.com | `finquesmarques_sql.py` | 59          | âœ… Funcionando |
| www.nouaire.com      | `nouaire_sql.py`        | 1,521       | âœ… Funcionando |
| www.expofinques.com  | `expofinques_sql.py`    | 56          | âœ… Funcionando |
| www.7claus.com       | `claus_sql.py`          | 12          | âœ… Funcionando |

**Total: 1,648 propiedades**

## ğŸš€ Uso

### ConfiguraciÃ³n inicial

```bash
# Clonar y setup
git clone <repo>
cd scraper-project

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# o .venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt

# Iniciar PostgreSQL
docker-compose up -d postgres
```

### Ejecutar scrapers

```bash
# Ejecutar todos los scrapers
python -m src.scrapers.runner

# Ejecutar scraper especÃ­fico
python -m src.scrapers.finquesmarques_sql
python -m src.scrapers.nouaire_sql
python -m src.scrapers.expofinques_sql
python -m src.scrapers.claus_sql
```

## ğŸ—„ï¸ Base de Datos

### Esquema de tabla `properties`

```sql
CREATE TABLE properties (
    id SERIAL PRIMARY KEY,
    price INTEGER,
    rooms INTEGER,
    bathrooms INTEGER,
    surface INTEGER,
    timestamp TIMESTAMP,
    website VARCHAR(255),
    title TEXT,
    reference VARCHAR(100),
    operation VARCHAR(50),
    location VARCHAR(255),
    address TEXT,
    url TEXT UNIQUE
);
```

### Consultas Ãºtiles

```sql
-- Resumen por website
SELECT website, COUNT(*) as total
FROM properties
GROUP BY website
ORDER BY total DESC;

-- Propiedades mÃ¡s caras
SELECT title, price, website
FROM properties
WHERE price > 0
ORDER BY price DESC
LIMIT 10;

-- EstadÃ­sticas por ubicaciÃ³n
SELECT location, COUNT(*) as total, AVG(price) as precio_promedio
FROM properties
WHERE location IS NOT NULL
GROUP BY location
ORDER BY total DESC;
```

## ğŸ³ Docker

### Servicios disponibles

- **postgres**: Base de datos PostgreSQL 14
- **scraper**: AplicaciÃ³n scraper (opcional)

### Variables de entorno

```bash
POSTGRES_USER=scraper_user
POSTGRES_PASSWORD=scraper_password
POSTGRES_DB=properties_db
```

## ğŸ”§ Desarrollo

### AÃ±adir nuevo scraper

1. Crear archivo en `src/scrapers/nuevo_scraper.py`
2. Implementar clase con mÃ©todo `run()`
3. AÃ±adir al runner en `src/scrapers/runner.py`
4. Usar `PropertyRepository` para guardar datos

### Estructura mÃ­nima de scraper

```python
from ..database.operations import PropertyRepository
from ..database.connection import create_tables

class NuevoScraper:
    def __init__(self):
        self.website = "www.ejemplo.com"

    def run(self):
        create_tables()
        property_repo = PropertyRepository()
        # ... lÃ³gica de scraping ...
        property_repo.save_property(data)
```

## ğŸ“ Archivos en `antic/`

- Versiones anteriores de scrapers
- Scripts de prueba y validaciÃ³n obsoletos
- Archivos de configuraciÃ³n corruptos
- Backups y cÃ³digo experimental

## ğŸ¤ Contribuir

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nuevo-scraper`)
3. Commit cambios (`git commit -am 'Add nuevo scraper'`)
4. Push a la rama (`git push origin feature/nuevo-scraper`)
5. Crear Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT.

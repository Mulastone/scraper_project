import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re
import unicodedata
from ..database.operations import PropertyRepository
from ..database.connection import create_tables
from ..utils.text_cleaner import limpiar_texto, extraer_precio, detectar_pas_de_la_casa, detectar_arinsal, detectar_bordes

class ClausScraper:
    def __init__(self):
        self.base_url = "http://www.7claus.com"
        self.listing_url = "http://www.7claus.com/cercador/pisos_duplex_apartaments_atics/andorra_andorra/"
        self.website = "www.7claus.com"
        
        # Ubicaciones v√°lidas de Andorra
        self.andorra_keywords = [
            'andorra', 'escaldes', 'engordany', 'sant julia', 'encamp', 'canillo', 
            'massana', 'ordino', 'pas de la casa', 'arinsal', 'bordes', 'envalira',
            'tarter', 'soldeu', 'incles', 'pal', 'serrat', 'les bons', 'santa coloma',
            'erts', 'llorts', 'sispony', 'ransol', 'aixovall', 'nagol'
        ]
    
    def is_andorra_location(self, location):
        """
        Verifica si una ubicaci√≥n pertenece a Andorra
        """
        if not location or location == 'N/A':
            return False
            
        location_lower = location.lower()
        
        # Verificar si contiene alguna palabra clave de Andorra
        return any(keyword in location_lower for keyword in self.andorra_keywords)
        
    def run(self):
        """
        Ejecuta el scraper principal
        """
        # Crear tablas si no existen
        create_tables()
        
        # Obtener las propiedades
        propiedades = self.obtener_propiedades()
        
        # Procesar cada propiedad
        property_repo = PropertyRepository()
        propiedades_procesadas = 0
        
        for propiedad in propiedades:
            try:
                # Extraer datos de la propiedad
                property_data = self.extract_property_data(propiedad)
                
                if property_data:
                    # Guardar la propiedad
                    if property_repo.save_property(property_data):
                        propiedades_procesadas += 1
                        print(f"‚úÖ Propiedad guardada: {property_data.get('titulo', 'Sin t√≠tulo')[:50]}...")
                    else:
                        print(f"‚ùå Error al guardar: {property_data.get('titulo', 'Sin t√≠tulo')[:50]}...")
                        
            except Exception as e:
                print(f"Error procesando propiedad: {e}")
        
        print(f"üèÅ Scraping completado. {propiedades_procesadas} propiedades procesadas")

    def obtener_propiedades(self):
        """Obtiene la lista de propiedades de la p√°gina de listado"""
        try:
            print(f"Obteniendo propiedades de: {self.listing_url}")
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            response = requests.get(self.listing_url, headers=headers)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            cards = soup.find_all('div', class_='cardAnuncio')
            
            print(f"Encontradas {len(cards)} propiedades")
            return cards
            
        except requests.RequestException as e:
            print(f"Error al obtener propiedades: {e}")
            return []

    def get_property_description(self, url_inmueble):
        """
        Obtiene la descripci√≥n completa de una propiedad espec√≠fica
        """
        try:
            response = requests.get(url_inmueble, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Buscar la descripci√≥n en diferentes posibles ubicaciones
            descripcion = ""
            
            # Buscar en div de descripci√≥n
            desc_div = soup.find('div', class_='descripcion')
            if desc_div:
                descripcion = desc_div.get_text(strip=True)
            
            # Si no se encontr√≥, buscar por otros selectores comunes
            if not descripcion:
                # Buscar en p√°rrafos largos
                paragrafos = soup.find_all('p')
                for p in paragrafos:
                    texto = p.get_text(strip=True)
                    if len(texto) > 100:
                        descripcion += " " + texto
            
            # Tambi√©n buscar en divs que contengan mucho texto
            if not descripcion:
                divs = soup.find_all('div')
                for div in divs:
                    texto = div.get_text(strip=True)
                    if len(texto) > 200 and ('ubicaci√≥n' in texto.lower() or 'situado' in texto.lower()):
                        descripcion = texto
                        break
            
            return descripcion.strip()
            
        except Exception as e:
            print(f"Error al obtener descripci√≥n de {url_inmueble}: {e}")
            return ""

    def extract_property_data(self, card):
        """Extrae los datos de una propiedad individual"""
        try:
            data = {
                'website': self.website,
                'timestamp': datetime.now(),
                'operation': 'Venta',  # La URL indica "en_venda"
                'address': 'N/A',
                'reference': 'N/A',
                'title': 'N/A',
                'location': 'N/A',
                'price': 0,
                'rooms': 0,
                'bathrooms': 0,
                'surface': 0,
                'url': 'N/A'
            }
            
            # T√≠tulo
            titulo_elem = card.find('span', class_='titulo')
            if titulo_elem:
                data['title'] = limpiar_texto(titulo_elem.get_text())
            
            # Referencia
            ref_elem = card.find('span', class_='contRef')
            if ref_elem:
                data['reference'] = limpiar_texto(ref_elem.get_text())
            
            # Precio
            precio_elem = card.find('div', class_='precio')
            if precio_elem:
                precio_text = precio_elem.get_text().strip().split('\n')[0].strip()
                data['price'] = extraer_precio(precio_text)
            
            # FILTRO 1: Saltar propiedades con precio mayor a 450,000‚Ç¨
            if data['price'] > 450000:
                print(f"‚ö†Ô∏è [CLAUS] Propiedad filtrada por precio alto: {data['price']:,.0f}‚Ç¨ > 450,000‚Ç¨")
                return None
            
            # Extraer ubicaci√≥n del t√≠tulo ANTES del filtro de Andorra
            if data['title'] != 'N/A':
                # El t√≠tulo suele tener formato "Pis a Carrer Sant Jordi"
                if ' a ' in data['title']:
                    parts = data['title'].split(' a ', 1)
                    if len(parts) > 1:
                        data['location'] = limpiar_texto(parts[1])
                
            # FILTRO 2: Verificar que la propiedad est√© en Andorra ANTES de detectar poblaciones especiales
            if not self.is_andorra_location(data['location']):
                print(f"üåç [CLAUS] Propiedad filtrada por estar fuera de Andorra: {data['location']}")
                return None            # Extraer caracter√≠sticas (habitaciones, ba√±os, superficie)
            props = card.find_all('li')
            for prop in props:
                divs = prop.find_all('div')
                if len(divs) == 2:
                    key = divs[0].get_text().strip()
                    value = divs[1].get_text().strip()
                    
                    if 'Habs' in key:
                        try:
                            data['rooms'] = int(value)
                        except (ValueError, TypeError):
                            data['rooms'] = 0
                    elif 'Banys' in key:
                        try:
                            data['bathrooms'] = int(value)
                        except (ValueError, TypeError):
                            data['bathrooms'] = 0
                    elif 'm¬≤' in key or 'm2' in key:
                        try:
                            # Soportar decimales (coma o punto)
                            value_clean = value.replace(',', '.')
                            data['surface'] = float(value_clean)
                        except (ValueError, TypeError):
                            data['surface'] = 0
            
            # URL de detalle desde el bot√≥n de contacto
            btn_contacto = card.find('div', class_='btnContacto')
            if btn_contacto and btn_contacto.get('data-url'):
                detail_path = btn_contacto['data-url'].split('#')[0]
                data['url'] = f"{self.base_url}{detail_path}"
            
            # FILTRO 3: Detectar poblaciones especiales DESPU√âS de confirmar que est√° en Andorra
            
            # Verificar Pas de la Casa (Encamp o ubicaciones gen√©ricas)
            if data['location'] and ('encamp' in data['location'].lower() or 'andorra' in data['location'].lower() or data['location'] == 'N/A'):
                print(f"üîç [CLAUS] Verificando descripci√≥n para posible Pas de la Casa: {data['url']}")
                descripcion = self.get_property_description(data['url'])
                
                if descripcion and detectar_pas_de_la_casa(descripcion):
                    print(f"‚úÖ [CLAUS] ¬°Detectado Pas de la Casa en descripci√≥n! Cambiando ubicaci√≥n de '{data['location']}' a 'Pas de la Casa'")
                    data['location'] = "Pas de la Casa"
                else:
                    print(f"‚ùå [CLAUS] No se detect√≥ Pas de la Casa en la descripci√≥n")
            
            # Verificar Arinsal (La Massana o Arinsal directo)
            elif data['location'] and ('massana' in data['location'].lower() or 'arinsal' in data['location'].lower()):
                print(f"üîç [CLAUS] Verificando descripci√≥n para posible Arinsal: {data['url']}")
                descripcion = self.get_property_description(data['url'])
                
                if descripcion and detectar_arinsal(descripcion):
                    print(f"‚úÖ [CLAUS] ¬°Detectado Arinsal en descripci√≥n! Cambiando ubicaci√≥n de '{data['location']}' a 'Arinsal'")
                    data['location'] = "Arinsal"
                else:
                    print(f"‚ùå [CLAUS] No se detect√≥ Arinsal en la descripci√≥n")
            
            # Verificar Bordes d'Envalira (Canillo, Soldeu, etc.)
            elif data['location'] and ('canillo' in data['location'].lower() or 'soldeu' in data['location'].lower() or 
                                     'incles' in data['location'].lower() or 'tarter' in data['location'].lower() or
                                     'bordes' in data['location'].lower()):
                print(f"üîç [CLAUS] Verificando descripci√≥n para posible Bordes d'Envalira: {data['url']}")
                descripcion = self.get_property_description(data['url'])
                
                if descripcion and detectar_bordes(descripcion):
                    print(f"‚úÖ [CLAUS] ¬°Detectado Bordes d'Envalira en descripci√≥n! Cambiando ubicaci√≥n de '{data['location']}' a 'Bordes d\\'Envalira'")
                    data['location'] = "Bordes d'Envalira"
                else:
                    print(f"‚ùå [CLAUS] No se detect√≥ Bordes d'Envalira en la descripci√≥n")
            else:
                print(f"‚ÑπÔ∏è [CLAUS] Ubicaci√≥n '{data['location']}' no necesita verificaci√≥n")
            
            # Verificar que tenemos datos m√≠nimos
            if data['title'] == 'N/A' or data['price'] == 0:
                return None
                
            return data
            
        except Exception as e:
            print(f"Error al extraer datos de propiedad: {e}")
            return None


if __name__ == "__main__":
    print("üè† Iniciando scraper de 7 Claus...")
    scraper = ClausScraper()
    scraper.run()
    print("‚ú® Scraping de 7 Claus completado")
# üè† Dashboard Propiedades Andorra - Sistema Automatizado

Dashboard interactivo para visualizaci√≥n de propiedades inmobiliarias en Andorra con scrapers automatizados, sistema de vigencia, filtrado optimizado y interfaz web moderna.

![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=for-the-badge&logo=postgresql&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

**üåç Demo Live**: [pisos.arasmu.net](https://pisos.arasmu.net)

## üéØ Estado Actual (Octubre 2025)

‚úÖ **Sistema Completamente Automatizado**  
‚úÖ **339 Propiedades Activas** (solo Andorra)  
‚úÖ **4 Scrapers Optimizados** con filtrado inteligente  
‚úÖ **Sistema de Vigencia** (3 d√≠as)  
‚úÖ **Filtros por Ubicaciones Especiales** (Pas de la Casa, Arinsal, Bordes d'Envalira)  
‚úÖ **Batch Processing Optimizado**  
‚úÖ **SSL & Dominio pisos.arasmu.net**  
‚úÖ **Cron Diario Autom√°tico** (06:00)

## üèóÔ∏è Arquitectura del Sistema

```
scraper-project/
‚îú‚îÄ‚îÄ üóÑÔ∏è Base de Datos (PostgreSQL)
‚îÇ   ‚îî‚îÄ‚îÄ properties_db (339 propiedades filtradas)
‚îú‚îÄ‚îÄ üï∑Ô∏è Scrapers Python Optimizados
‚îÇ   ‚îú‚îÄ‚îÄ pisosad_sql.py        # Scraper pisos.ad (‚Ç¨10k-‚Ç¨450k)
‚îÇ   ‚îú‚îÄ‚îÄ nouaire_sql.py        # Scraper principal (1,500+ URLs)
‚îÇ   ‚îú‚îÄ‚îÄ expofinques_sql.py    # Scraper expofinques
‚îÇ   ‚îî‚îÄ‚îÄ claus_sql.py         # Scraper 7claus
‚îú‚îÄ‚îÄ üìä Dashboard (Streamlit)
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py     # Interfaz web con logo ARASMU
‚îú‚îÄ‚îÄ üê≥ Docker Containers
‚îÇ   ‚îú‚îÄ‚îÄ pisos_streamlit_prod # Dashboard web (puerto 8501)
‚îÇ   ‚îî‚îÄ‚îÄ ecodisseny_dj_pg_db_1 # PostgreSQL
‚îú‚îÄ‚îÄ ü§ñ Automatizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ run_all_scrapers.sh  # Script principal
‚îÇ   ‚îú‚îÄ‚îÄ setup_cron.sh        # Cron diario 06:00
‚îÇ   ‚îî‚îÄ‚îÄ test_vigencia.sh     # Tests sistema vigencia
‚îî‚îÄ‚îÄ üåê Nginx Proxy
    ‚îî‚îÄ‚îÄ SSL con Let's Encrypt
```

## üéØ Scrapers Optimizados

| Sitio Web | Scraper | Estado | Filtros Aplicados |
|-----------|---------|--------|-------------------|
| **pisos.ad** | `pisosad_sql.py` | ‚úÖ **100% Funcional** | Precio ‚Ç¨10k-‚Ç¨450k + Andorra |
| **nouaire.com** | `nouaire_sql.py` | ‚úÖ Funcionando | Detecta ubicaciones especiales |
| **expofinques.com** | `expofinques_sql.py` | ‚úÖ Funcionando | Filtro Andorra + precio |
| **7claus.com** | `claus_sql.py` | ‚úÖ Funcionando | Validaci√≥n ubicaci√≥n |

### üéØ Filtrado Inteligente Implementado

**Sistema de 3 Etapas:**
1. **Filtro Precio**: Solo propiedades ‚â§ ‚Ç¨450,000
2. **Filtro Andorra**: Validaci√≥n pa√≠s con `is_andorra_location()`
3. **Detecci√≥n Especial**: Pas de la Casa, Arinsal, Bordes d'Envalira

**Palabras clave Andorra:**
```python
andorra_keywords = [
    'andorra', 'escaldes', 'engordany', 'encamp', 'ordino', 
    'canillo', 'massana', 'sant julia', 'loria', 'la vella'
]
```

## üöÄ Instalaci√≥n y Configuraci√≥n

### Prerequisitos
- Docker & Docker Compose
- PostgreSQL (contenedor compartido)
- Nginx con SSL
- Python 3.12+

### üê≥ Configuraci√≥n Docker

```bash
# 1. Construir imagen Streamlit
docker build -f docker/Dockerfile.streamlit -t scraper_project-streamlit .

# 2. Ejecutar contenedor con network host
docker run -d --name pisos_streamlit_prod \
  --network host \
  -e DATABASE_URL="postgresql://scraper_user:scraper_password@localhost:5432/properties_db" \
  scraper_project-streamlit
```

### üóÑÔ∏è Base de Datos

```sql
-- Esquema optimizado con sistema de vigencia
CREATE TABLE properties (
    id SERIAL PRIMARY KEY,
    price INTEGER NOT NULL,
    rooms INTEGER,
    bathrooms INTEGER,
    surface REAL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    vigencia_date DATE DEFAULT CURRENT_DATE,  -- NUEVO: Sistema vigencia
    website VARCHAR(255) NOT NULL,
    title TEXT NOT NULL,
    reference VARCHAR(100),
    operation VARCHAR(50) DEFAULT 'venta',
    location VARCHAR(255),
    address TEXT,
    url TEXT UNIQUE NOT NULL
);

-- √çndices para rendimiento
CREATE INDEX idx_properties_vigencia ON properties(vigencia_date);
CREATE INDEX idx_properties_price ON properties(price);
CREATE INDEX idx_properties_location ON properties(location);
```

### ü§ñ Automatizaci√≥n con Cron

```bash
# Configurar cron diario
chmod +x setup_cron.sh
./setup_cron.sh

# Cron programado: 0 6 * * * (06:00 diario)
crontab -l
```

## üìä Dashboard Streamlit

### Caracter√≠sticas Principales

- **üé® Logo ARASMU** en parte superior del sidebar
- **üèòÔ∏è Filtro Poblaciones Invertido**: Por defecto excluye Pas de la Casa, Arinsal, Bordes d'Envalira
- **üí∞ Rango de Precios**: ‚Ç¨10,000 - ‚Ç¨450,000
- **üè† Tipos de Propiedad**: Residenciales por defecto
- **üì± Responsive Design**

### Filtros Implementados

```python
# Tipos residenciales por defecto
tipos_residenciales = ['Piso', 'Apartamento', 'Estudio', 'Duplex', 'Planta baja', '√Åtico']

# Poblaciones excluidas por defecto
poblaciones_especiales = ['Pas de la Casa', 'Arinsal', 'Bordes d\'Envalira']
poblaciones_por_defecto = [pob for pob in poblaciones_disponibles 
                          if pob not in poblaciones_especiales]
```

## üåê Configuraci√≥n Nginx

```nginx
# /etc/nginx/sites-enabled/pisos.arasmu.net
server {
    server_name pisos.arasmu.net;
    
    location / {
        proxy_pass http://127.0.0.1:8501/;  # Puerto actualizado
        
        # Headers para Streamlit
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Timeouts
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 300s;
        
        proxy_buffering off;
        proxy_cache_bypass $http_upgrade;
    }

    listen 443 ssl;
    ssl_certificate /etc/letsencrypt/live/pisos.arasmu.net/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/pisos.arasmu.net/privkey.pem;
}
```

## üîß Scripts de Gesti√≥n

### Scripts Principales

```bash
# Ejecutar todos los scrapers
./run_all_scrapers.sh

# Configurar cron autom√°tico
./setup_cron.sh

# Test sistema de vigencia
./test_vigencia.sh

# Limpiar base de datos
python clear_database.py
```

### Comandos Docker √ötiles

```bash
# Estado de contenedores
docker ps | grep pisos

# Logs en tiempo real
docker logs -f pisos_streamlit_prod

# Recrear contenedor Streamlit
docker stop pisos_streamlit_prod && docker rm pisos_streamlit_prod
docker run -d --name pisos_streamlit_prod --network host \
  -e DATABASE_URL="postgresql://scraper_user:scraper_password@localhost:5432/properties_db" \
  scraper_project-streamlit

# Reiniciar nginx
sudo systemctl reload nginx
```

## üîç Sistema de Vigencia

**Funcionamiento:**
- Cada propiedad tiene `vigencia_date = CURRENT_DATE`
- Scrapers actualizan vigencia si URL ya existe
- Propiedades > 3 d√≠as se marcan como obsoletas
- Batch processing optimizado para performance

```python
# Actualizaci√≥n de vigencia
cursor.execute("""
    UPDATE properties 
    SET vigencia_date = CURRENT_DATE 
    WHERE url = %s
""", (url,))
```

## üõ†Ô∏è Soluci√≥n de Problemas

### Problemas Comunes

1. **Error credenciales PostgreSQL**
   ```bash
   # Resetear contrase√±a usuario scraper_user
   docker exec ecodisseny_dj_pg_db_1 psql -U ecodisseny_user -d ecodisseny_db \
     -c "ALTER USER scraper_user PASSWORD 'scraper_password';"
   ```

2. **Nginx 502 Bad Gateway**
   ```bash
   # Verificar puerto correcto en nginx config
   sudo sed -i 's|8518|8501|g' /etc/nginx/sites-enabled/pisos.arasmu.net
   sudo systemctl reload nginx
   ```

3. **Scrapers fallan con variable scope error**
   ```bash
   # Verificar que variables est√©n declaradas antes de uso
   # En pisosad_sql.py: extraer ubicaci√≥n ANTES de filtros
   ```

### Debug Commands

```bash
# Test conexi√≥n BD desde contenedor
docker exec pisos_streamlit_prod python -c "
from sqlalchemy import create_engine, text
engine = create_engine('postgresql://scraper_user:scraper_password@localhost:5432/properties_db')
with engine.connect() as conn:
    result = conn.execute(text('SELECT count(*) FROM properties'))
    print(f'Propiedades: {result.fetchone()[0]}')
"

# Verificar scrapers
python -c "from src.scrapers.runner import run_all_scrapers; run_all_scrapers()"
```

## üìà Estad√≠sticas del Sistema

**Base de Datos Optimizada:**
- **Antes**: 696 propiedades (muchas fuera de Andorra)
- **Despu√©s**: 339 propiedades (100% Andorra)
- **Filtradas**: 371 propiedades no v√°lidas eliminadas

**Performance:**
- **Tiempo scraping**: ~7-8 minutos para todos los scrapers
- **Batch processing**: Inserci√≥n optimizada por lotes
- **Sistema vigencia**: Actualizaciones eficientes

## ü§ù Contribuci√≥n

1. Fork del proyecto
2. Crear rama feature (`git checkout -b feature/nuevo-filtro`)
3. Commit cambios (`git commit -m 'Add: filtro por superficie'`)
4. Push (`git push origin feature/nuevo-filtro`)
5. Crear Pull Request

## üìÑ Licencia

MIT License - Ver `LICENSE` para detalles.

---

**Desarrollado con ‚ù§Ô∏è por Arasmu** | **Dashboard Live**: [pisos.arasmu.net](https://pisos.arasmu.net)

**üîÑ √öltima actualizaci√≥n**: Octubre 2025 - Sistema completamente automatizado y optimizado
| 7claus.com | `claus_sql.py` | 12 | ‚Ç¨200k - ‚Ç¨600k | ‚úÖ Funcionando |

### üéØ pisos.ad - Scraper Premium

- **Estrategia Multi-Range**: 3 rangos de precio (10K-400K, 400K-1M, 1M+)
- **Extracci√≥n Avanzada**: BeautifulSoup + regex patterns
- **Precios Reales**: ‚Ç¨127,000 - ‚Ç¨9,500,000 (100% precisi√≥n)
- **Deduplicaci√≥n**: Por URL √∫nica
- **Datos Completos**: Precio, habitaciones, ba√±os, superficie, ubicaci√≥n

**Total Sistema: 1,683 propiedades**

## üöÄ Dashboard Interactivo

### üìä Funcionalidades Principales

- **üè† Filtros Inteligentes**: Por tipo (Piso, Apartamento, Estudio, etc.)
- **üí∞ Rangos de Precio**: 10K‚Ç¨ - 450K‚Ç¨ (personalizable)
- **üìç Ubicaciones**: Todas las parroquias de Andorra
- **üìà Visualizaciones**: Gr√°ficos de barras, mapas de calor
- **üîç B√∫squeda Avanzada**: Por superficie, habitaciones, ba√±os
- **üìã Lista Detallada**: Con enlaces directos a propiedades

### üé® Interfaz de Usuario

- **Dise√±o Responsivo**: Optimizado para desktop y m√≥vil
- **Sidebar Compacto**: Filtros organizados con logo Arasmu
- **Sin Elementos Debug**: Interfaz limpia y profesional
- **Carga Autom√°tica**: Datos frescos sin botones innecesarios

## üê≥ Despliegue Docker

### Contenedores en Producci√≥n

```bash
# Dashboard Streamlit
pisos_streamlit_prod:
  - Puerto: 127.0.0.1:8518:8501
  - Red: ecodisseny_dj_pg_default
  - BD: ecodisseny_user:ecodisseny_password123

# Scrapers (manual)
pisos_scraper_prod:
  - Ejecuci√≥n bajo demanda
  - Misma red y BD

# PostgreSQL (externo)
ecodisseny_dj_pg_db_1:
  - Puerto: 5432
  - BD: properties_db
  - Usuario: ecodisseny_user
```

### üåê Configuraci√≥n Nginx

```nginx
# Acceso principal
location /pisos {
    proxy_pass http://localhost:8518/pisos;
    # WebSocket support para Streamlit
}

# Recursos est√°ticos
location ~ ^/pisos/static/.*$ {
    proxy_pass http://localhost:8518;
    expires 1y;
}

# Redirecci√≥n autom√°tica
location = / {
    return 301 /pisos/;
}
```

## üóÑÔ∏è Esquema de Base de Datos

```sql
CREATE TABLE properties (
    id SERIAL PRIMARY KEY,
    price INTEGER NOT NULL,
    rooms INTEGER,
    bathrooms INTEGER,
    surface INTEGER,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    website VARCHAR(255) NOT NULL,
    title TEXT NOT NULL,
    reference VARCHAR(100),
    operation VARCHAR(50),
    location VARCHAR(255),
    address TEXT,
    url TEXT UNIQUE NOT NULL
);

-- √çndices para rendimiento
CREATE INDEX idx_properties_price ON properties(price);
CREATE INDEX idx_properties_website ON properties(website);
CREATE INDEX idx_properties_location ON properties(location);
```

## üöÄ Scripts de Despliegue

### Despliegue Local
```bash
# Setup completo
./deploy-local.sh

# Solo dashboard
docker-compose -f docker-compose.shared-db.yml up -d
```

### Despliegue desde GitHub
```bash
# Deploy autom√°tico
./deploy-from-github.sh

# Actualizaci√≥n
./update-from-github.sh
```

### SSL y Dominio
```bash
# Setup DNS (manual en Cloudflare)
# pisos.arasmu.net ‚Üí 161.97.147.142

# SSL Certificate (despu√©s de DNS propagation)
./setup-pisos-ssl.sh
```

## üîß Desarrollo y Mantenimiento

### Ejecutar Scrapers Manualmente

```bash
# Todos los scrapers
docker exec pisos_scraper_prod python -m src.scrapers.runner

# Scraper espec√≠fico
docker exec pisos_scraper_prod python -m src.scrapers.pisosad_sql
```

### Consultas √ötiles PostgreSQL

```sql
-- Estado actual
SELECT website, COUNT(*) as propiedades, 
       MIN(price) as precio_min, MAX(price) as precio_max
FROM properties 
WHERE price > 0
GROUP BY website 
ORDER BY propiedades DESC;

-- Propiedades pisos.ad
SELECT title, price, rooms, surface, location, url
FROM properties 
WHERE website = 'pisos.ad'
ORDER BY price DESC;

-- Estad√≠sticas por parroquia
SELECT location, COUNT(*) as total, 
       AVG(price)::INTEGER as precio_promedio
FROM properties 
WHERE location LIKE '%Andorra%'
GROUP BY location 
ORDER BY total DESC;
```

### Debugging y Logs

```bash
# Logs del dashboard
docker logs pisos_streamlit_prod

# Logs de scrapers
docker logs pisos_scraper_prod

# Acceso a PostgreSQL
docker exec -it ecodisseny_dj_pg_db_1 psql -U ecodisseny_user -d properties_db
```

## üìä Monitorizaci√≥n

### M√©tricas Actuales (Sep 2025)

- **üìà Total Propiedades**: 1,683
- **üí∞ Rango Precios**: ‚Ç¨85,000 - ‚Ç¨9,500,000  
- **üè† Tipos**: 15+ categor√≠as (Piso, Apartamento, etc.)
- **üìç Ubicaciones**: 7 parroquias + subcategor√≠as
- **‚ö° Tiempo Carga**: <3 segundos
- **üîÑ Actualizaci√≥n**: Manual bajo demanda

### Health Checks

```bash
# Verificar dashboard
curl -I http://161.97.147.142/pisos/

# Verificar base de datos
docker exec ecodisseny_dj_pg_db_1 pg_isready -U ecodisseny_user

# Verificar contenedores
docker ps | grep pisos
```

## üõ†Ô∏è Soluci√≥n de Problemas

### Problemas Comunes

1. **Dashboard en blanco**: Verificar conexi√≥n BD y credenciales
2. **Filtros no funcionan**: Limpiar cach√© Streamlit
3. **Scrapers fallan**: Verificar estructura HTML de sitios
4. **Nginx 502**: Verificar que contenedor Streamlit est√© ejecut√°ndose

### Recovery Commands

```bash
# Reiniciar dashboard
docker restart pisos_streamlit_prod

# Reconstruir desde cero
docker-compose -f docker-compose.shared-db.yml down
docker-compose -f docker-compose.shared-db.yml up -d --build

# Limpiar sistema Docker
docker system prune -f
```

## üîê Configuraci√≥n SSL

### Certificados Let's Encrypt

```bash
# Despu√©s de DNS propagation
sudo certbot --nginx -d pisos.arasmu.net

# Auto-renovaci√≥n
sudo crontab -e
# 0 12 * * * /usr/bin/certbot renew --quiet
```

## üìà Roadmap Futuro

- [ ] **Scrapers Adicionales**: M√°s portales inmobiliarios
- [ ] **API REST**: Endpoint p√∫blico para datos
- [ ] **Alertas Email**: Notificaciones de nuevas propiedades
- [ ] **Machine Learning**: Predicci√≥n de precios
- [ ] **Mobile App**: Aplicaci√≥n nativa
- [ ] **Multi-idioma**: Catal√°n, franc√©s, ingl√©s

## ü§ù Contribuci√≥n

1. Fork del proyecto
2. Crear rama feature (`git checkout -b feature/nuevo-scraper`)
3. Commit cambios (`git commit -m 'Add: nuevo scraper pisos.com'`)
4. Push (`git push origin feature/nuevo-scraper`)
5. Crear Pull Request

## üìÑ Licencia

MIT License - Ver `LICENSE` para detalles.

---

**Desarrollado con ‚ù§Ô∏è por Arasmu** | **Dashboard Live**: [pisos.arasmu.net](https://pisos.arasmu.net)